---
title: "Wrangling data in R"
output: 
  learnr::tutorial:
    progresive: true
runtime: shiny_prerendered
---

```{r setup, include = FALSE}
library(learnr)
library(knitr)
```

# **Week 2:** Wrangling data in R

#### ANTH 674: Research Design and Analysis in Anthropology
#### Professor Andrew Du


## Introduction

This week is all about wrangling data in R. 
**Data wrangling** is the process of cleaning and organizing raw data into a format that is suitable for your analyses.
Many data scientists only wrangle data for their companies (i.e., they don't analyze data), so this is a very marketable skill!
As you will see, there are all kinds of errors and issues in raw data that need to be fixed before data analysis can begin.

![](https://22570l2e793j2oo9c81ug2nh-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/data-wrangling-how-to-do-effectively.jpg){width="70%"}

R "automates" the data wrangling process by using code to clean data en masse.
This way, you don't have to fix every single data entry by hand, which is time-consuming and increases the likelihood that you will create data errors because humans are fallible.
Moreover, your written and saved R code acts as a record of what you did, so your data wrangling is now transparent and replicable.    

Even better is entering your data into spreadsheets in a format that is already clean.
You will learn what "clean" means by dealing with data issues in this R tutorial.
As mentioned in lecture, how R handles names, numbers, etc. is how data should be structured.
As a result, you will learn what good data practices are just from being an R user!

Note that I will teach you how to wrangle data using R's base language, building upon what you learned in last week's tutorial.
There is an R package `dplyr` ([more information here](https://dplyr.tidyverse.org)) that is now commonly used for data wrangling.
There is a learning curve involved, but I would encourage you to learn `dplyr` if you need to do some heavy-duty wrangling or if you work with really large datasets.
For what it's worth, I myself do not know `dplyr` that well, and I have gotten away with using base R for data wrangling (so far).


## Goals for this tutorial

#### 1) Continue to familiarize yourself with R.
#### 2) Learn the relevant functions and ways for wrangling data in R.
#### 3) Reinforce what clean data is by cleaning data in R.


## Sorting data

Key in data wrangling is being able to manipulate data.
This includes sorting data, which you were already exposed to in last week's homework.
We will learn some additional functions for sorting data.

Let's start with a vector `x <- c(3, 1, 3, 10)`.

The `sort()` function creates an output vector where the elements are sorted in ascending order.
How would you sort a vector, using `sort()`, wherein the elements are in *descending* order?
*Hint*: look at the help file.

`order()` returns a vector of rank orders.
Try it out on `x` below.

```{r sorting, exercise = TRUE}
```

You can see that `order()` handles ties by assigning a lower rank to the tied number that comes first (e.g., the first `3` gets a `2`, while the second `3` gets a `3`).

`rank()` will return a vector of rank orders with ties averaged.
Try it out on `x`.

Why might `order()` and `rank()` be useful in data wrangling?
Imagine if you had to reorder data for one variable according to the order of numbers in another variable.
Recalling that data within a vector can be ordered/subset using indexes (e.g., `c(1, 2, 4)[3]` returns `4`, and `c(1, 2, 4)[c(3, 2, 1)]` returns `4 2 1`), the rank orders provided by these functions act as indexes for reordering/subsetting another vector. 

For example, let's say I had two vectors: fossil specimen ID number and year of discovery.
I can use `order()` to easily order fossil specimen ID numbers according to the year they were discovered: `spec_ID[order(year_disc)]`.
You can also reorder an entire dataframe in the same way.
For example, if I wanted to reorder the rows in `mtcars` by increasing weight (`wt`), I would enter `mtcars[order(mtcars$wt), ]`.
Recall that for two-dimensional R objects, code before the `,` applies to rows, while code after the `,` applies to columns.


## Subsetting data

Subsetting data is important in data wrangling because there are likely observations and variables in the raw dataset that are not of interest to you.
That is, you want to be able to extract data that is relevant to your research question only.

We already learned some ways to subset data in last week's tutorial using `[]`, and here I will introduce some additional functions.
You will see that for the most part, these functions do the same thing as `[]` or other previously introduced code, so it is up to you which piece of code you prefer to use.

### Using `which()`

`which()` returns the indexes of elements that are `TRUE` within a logical vector.
For example, take the vector `x <- c(FALSE, TRUE, FALSE)`.
What do you think you'll get when you enter in `which(x)`?

```{r which, exercise = TRUE}
```

Thus, `which()` returns the indexes of elements within a vector that pass some logical statement.
For example, take the vector `x <- 20:30`.
What do you think you'll get when you enter `which(x > 25)`?
Recalling that you can subset a vector with indexes, you can subset out the elements that are greater than 25 using `x[which(x > 25)]`.
Of course, you can achieve the same thing, cutting out the middleman, using the original vector of `TRUE` and `FALSE`, i.e., `x[x > 25]`.

**NB:** `length(which())` tells you how many `TRUE` are in a logical vector, which can also be achieved with `sum()`. 

We can also delete elements from a vector using `which()`.
Recall that you use `-` to delete elements from a vector by index.
For example, if we wanted to delete the third element from a vector `x`, we would enter `x[-3]`.
Thus, you can use `which()` to indicate which elements you want to delete.
For example, if we wanted to *delete* elements greater than 25, we would enter `x[-which(x > 25)]`.
Of course, the same result can be achieved with `x[which(x < 25)]` or `x[x < 25]`.
Also with `x[!(x > 25)]`, where `!` indicates "not" in logical statements and transforms all `TRUE` to `FALSE`, and vice versa.

**Remember, there are many ways to do the same thing in R, so pick the one that works best with how you think!**

### Using `subset()`

`subset()` is a function that can be used to subset a vector or variables within a dataframe according to some logical statement.
Start with the vector `x <- 20:30` again.
Let's say we want to again subset out the elements that are greater than 25, but this time we'll use `subset()`.
The first argument is the R object you want to subset (i.e., `x`), and the second argument is the logical statement indicating which elements you want to subset (i.e., `x > 25`).
So, we want to enter `subset(x, x > 25)`.
Try it out below.

```{r subset, exercise = TRUE}
```

Note that `subset(x, x > 25)` is the same as `x[x > 25]` or `x[which(x> 25)]`.
For what it's worth, I use `x[x > 25]`. 

`subset()` is more useful for subsetting variables within a dataframe.
Let's work again with the `mtcars` dataset built into R.
**NB:** before, I told you to load the dataset into R with `data(mtcars)`.
I think the newest version of R already has all its datasets pre-loaded, so no need for this extra line of code now!

Let's say we want to subset out fuel efficiency (`mpg`) for those car models whose weights (`wt`) are below `3` (i.e., 3000 lbs.).
Remember that the first argument is the R object we want to subset (i.e., the `mtcars` dataframe), the second argument is the logical statement indicating which elements (or in this case, rows) to keep (i.e., `wt < 3`), and we need a third argument indicating which columns to select (i.e., `mpg`).
So, the proper code is `subset(mtcars, wt < 3, mpg)`.
Try it out above.
Note that this is the same as using `mtcars$mpg[mtcars$wt < 3]` or `mtcars$mpg[which(mtcars$wt < 3)]`. 
Use whichever method is more sensible to you!

We can also delete variables from a dataframe using `subset()`.
Let's say we wanted to delete the `wt` variable from `mtcars`.
The code for doing so is `subset(mtcars, select = -wt)`, remembering that `-` can be used to delete things.
Note that we had to explicitly define the third argument (i.e., `select`, indicating which columns to retain) because we skipped over the second argument (i.e., `subset`, a logical statement indicating which rows to subset).
If we did not do this, R would return an error thinking that `-wt` was meant for the second argument, which requires a logical statement for subsetting.
See what happens when you enter `subset(mtcars, -wt)`.
See the help file for `subset()` for more information on its arguments and their order.

Deletion of the `wt` variable can also be achieved with `mtcars[, colnames(mtcars) != "wt"]`, where `colnames()` brings up the variable names of `mtcars`.
Recall that for two-dimensional R objects, code before the `,` applies to rows, while code after the `,` applies to columns.

We can also use `subset()` to subset out multiple variables (i.e., columns) from a dataframe according to some logical statement.
Let's say we wanted to subset out *both* fuel efficiency (`mpg`) *and* horsepower (`hp`) for those car models whose weights (`wt`) are below `3` (i.e., 3000 lbs.).
We would enter `subset(mtcars, wt < 3, c(mpg, hp))`.
Try it out below.

```{r subset_mult, exercise = TRUE}
```

The result is a new dataframe with just two variables (`mpg` and `hp`) for those car models whose weight (`wt`) is below 3000 lbs.
The equivalent R code using `[]` is `mtcars[mtcars$wt < 3, c("mpg", "hp")]`.


## Combining rows and columns

During data wrangling, not only are we interested in subsetting out rows and columns, but we might be interested in adding rows and columns.

For example, let's imagine that the `mtcars` dataset did not include `wt`, but instead weight data was located in another dataset.
I've simulated this situation for you by creating a new dataframe called `mtcars_no_wt`, which has all the original `mtcars` variables except for `wt`. 
I've also created a new vector, `car_wt`, which has all the weights from `mtcars`.

```{r mtcars_no_wt-setup}
mtcars_no_wt <- subset(mtcars, select = -wt)
car_wt <- mtcars$wt
```

Let's say we wanted to take our car weight data from `car_wt` and add it as a new column/variable to `mtcars_no_wt`.
*As long as* `length(car_wt)` *equals the number of rows in* `mtcars_no_wt` (i.e., `length(car_wt) == nrow(mtcars_no_wt)`), we can use `cbind()` to combine `car_wt` with the columns in `mtcars_no_wt`.
This is done with `cbind(mtcars_no_wt, car_wt)`.
Try it out below.

```{r mtcars_no_wt, exercise = TRUE}
```

`cbind()` doesn't only have to be used for combining a vector with a dataframe, it can also be used to combine multiple dataframes or a matrix with a dataframe, as long as they all have the same number of rows.
Just for fun, try combining `mtcars` with itself using `cbind(mtcars, mtcars)` and see what happens.

We can also add rows to a vector, matrix, or dataframe using `rbind()`, as long as they all have the same number of columns.
For example, let's create a matrix with 3 rows and 4 columns: `XX <- matrix(1:12, nrow = 3, ncol = 4)`.
Now take the vector `x <- 1:4` and add it as a new row to `XX`, using `rbind(XX,x)`.
Try this out below.

```{r rbind, exercise = TRUE}
```


## Exercise 1: Data manipulation

We will work with the `iris` dataset this time.

1. Create a new dataframe called `iris.sepal_setosa` wherein the variables include only `Sepal.Length` and `Sepal.Width` for the `setosa` species only.
Next, sort the rows in `iris.sepal_setosa` by *decreasing* `Sepal.Length`, and save the result to a new dataframe called `iris.sepal_setosa_ordered`.

2. Let's create a new vector called `Sepal.Area`, which is equal to `Sepal.Length` times `Sepal.Width`, using data from our new `iris.sepal_setosa_ordered` dataframe. Add `Sepal.Area` as a new column to `iris.sepal_setosa_ordered`, and save this new dataframe as `iris.sepal_setosa_ordered1`.

```{r exer1, exercise = TRUE}
# You can click the "Solution" button for the answers when you're done.
```

```{r exer1-solution}
# Question 1a. 
iris.sepal_setosa <- subset(iris, Species == "setosa", c(Sepal.Length, Sepal.Width))
# Question 1b. 
iris.sepal_setosa_ordered <- iris.sepal_setosa[order(iris.sepal_setosa$Sepal.Length, decreasing = TRUE), ] 
# Question 2a. 
Sepal.Area <- iris.sepal_setosa_ordered$Sepal.Length * iris.sepal_setosa_ordered$Sepal.Width
# Question 2b. 
iris.sepal_setosa_ordered1 <- cbind(iris.sepal_setosa_ordered, Sepal.Area)
```


## What are factors?

The first rule for data organization from the lecture is to "Make sure your names are always *consistent*."
Inconsistent names can be a real headache in R, and we will see why shortly.
But first, we have to learn how R represents and handles names.

Names are also known as **categorial data** in statistics, which are defined as labels assigning each observation to a particular group (e.g., "juvenile" and "adult", assigning individuals to an age category).
We will learn more about categorical data next lecture when we cover data types.

Categorical data are represented as **factors** in R.
Factors can be numbers but are more commonly characters (e.g., `setosa`), and they have different **levels** (e.g., `juvenile` and `adult` are two different levels).

For example, the `Species` variable in the `iris` dataset is a factor.
You can see this by using the `class()` function to see what kind of variable `Species` is: `class(iris$Species)`.
Try this out below.
For comparison, you can also see what kind of variable `Sepal.Length` is.

```{r factors, exercise = TRUE}
```

To see the different levels of `Species`, enter `levels(iris$Species)`.
You can see that there are three levels corresponding to the three different species in the `iris` dataset.

When you import data into R, any column with text data will usually be treated as a factor.
What exactly a factor is may be difficult to understand now, but it will become clearer when we actually analyze data.
For now, just know that names are represented as factors in R, and this can create unique challenges during data cleaning.


## Inconsistent names

Again, the first rule in data organization is keep your names *consistent.*
In R, *ANY* differences between names will be interpreted as different names entirely.

For example, `zebra` is different than `Zebra`, which is different than `zebra ` (the last one has a space at the end, which is invisible in factor form).
So if you wanted to subset a dataframe to include only those data associated with zebras, this can cause problems (you would have to do `species == "zebra" | species == "Zebra" | species == "zebra "`, which is a pain especially if zebra is mistyped in many other ways).

Instead, you want to clean the data and standardize all "zebra" names to be the same.
Let's go through how to do that.

I have created for you a vector (`x`) with "zebra" and "elephant" as different factor levels. 

```{r zebra-setup}
x <- factor(c(rep("zebra", 10), rep("Zebra", 6), rep("zebra ", 2), "zEbra", rep("elephant", 10)))
```

Enter `x` below.

```{r zebra, exercise = TRUE}
```

You can see that `x` is a vector of factors with five different levels: "elephant" spelled one way and "zebra" spelled four different ways.
This is quite common in "dirty" data, as data are mistyped all the time during data entry.

### Subsetting unique elements

We can use the `unique()` function to get out the unique elements in our vector (this function works for numbers too).
Wrapping `sort()` around `unique()`, i.e., `sort(unique())`, will bring up the unique elements in alphabetical order.
`table()` is another useful function which tabulates and counts unique elements.
Try these functions out below.

```{r uniq-setup, echo = FALSE}
x <- factor(c(rep("zebra", 10), rep("Zebra", 6), rep("zebra ", 2), "zEbra", rep("elephant", 10)))
```

```{r uniq, exercise = TRUE}
```

A nice was of detecting pesky spaces is to transform your factor levels into characters.
Do this using `as.character()` (with long vectors, it's easier on the eye to look at unique elements only by wrapping `as.character()` around `unique()`, i.e., `as.character(unique())`).
Try this out above.

We can now see that there is a `"zebra"`, as well as a `"zebra "`, which R is interpreting as two different names.
How do we standardize all these different iterations of "zebra"?

### Standardizing different names

Your best friends here are the `grep()` and `grepl()` functions.
`grep()` returns the indexes of elements whose names match some specified pattern.
`grepl()` does the same but returns a logical vector of `TRUE` and `FALSE`, where `TRUE` indicates matches to the specified pattern.

Let's try this out below.
We want to subset all the different iterations of "zebra" in `x`.
Thus, we would enter `grep("zebra", x, ignore.case = TRUE)`, where the first argument is the pattern to be matched against, the second argument is the vector to be investigated, and `ignore.case` indicates whether pattern matching is case sensitive.

```{r grep-setup, echo = FALSE}
x <- factor(c(rep("zebra", 10), rep("Zebra", 6), rep("zebra ", 2), "zEbra", rep("elephant", 10)))
```

```{r grep, exercise = TRUE}
```

<div id = "grep-hint">
`x[grep("zebra", x, ignore.case = TRUE)] <- "zebra"`
</div>

You can see that R automatically detected all the different iterations of "zebra"!
This is because our specified character string, `"zebra"`, was present in all iterations of "zebra", even when spaces were involved.
That is `"zebra"` is a subset of `"zebra "`; you can also try the pattern `"zeb"` or `"ebra"`, and you will see it gives the same result.
Setting the argument `ignore.case = TRUE` means we ignored capitalization so `Zebra` and `zEbra` were detected as well.
Try out the same line of code but use `grepl()` instead.

Now it is straightforward to replace all iterations of "zebra" in `x` with one name.
Can you come up with the proper code to do so (click the "Hint" button if you're stuck)?

Look at how easy that was!
One line of code, and we're all done!
Way easier than fixing everything by hand in the original spreadsheet.

However, you'll notice that if you enter `x` now, the other levels of mistyped "zebra" are still "in the system" (this is especially obvious if you enter `table(x)`). There is an easy fix: use the `droplevels()` function, so enter `x <- droplevels(x)`.

### Standardizing names to a new one

What if we wanted to standardize our species names to be capitalized (i.e., `Zebra` and `Elephant`)?
This is straightforward for "zebra" because there is already a capitalized `Zebra` in `x`, but there is no capitalized `Elephant` in our vector.
This is where the factor class of `x` can be a bit annoying.

Let's revisit our original `x` vector.
Try to replace `elephant` with `Elephant`.
What happens?

```{r new-setup, echo = FALSE}
x <- factor(c(rep("zebra", 10), rep("Zebra", 6), rep("zebra ", 2), "zEbra", rep("elephant", 10)))
```

```{r new, exercise = TRUE}
```

R returns a warning message, saying `invalid factor level, NA generated`.
This warning is basically saying that `Elephant` as a factor level is invalid because no such level exists in `x`, so it replaced `elephant` with `NA`s.
Not good (this is also why it's a good idea to save modified vectors as new ones, e.g., `x1`, in case something goes wrong)!

To create new factor levels, we have to first transform `x` into a vector of character strings (do you remember how to do that?).
Now, we can replace `"elephant"` with `"Elephant"`.
Try this out above.

To transform `x` back into factors, we have to use `as.factor()`.


## Missing data

Missing data in R is represented using `NA`s.
If there are blank cells in your spreadsheet (actual blanks, not cells with a space!), R will automatically transform them into `NA`s when you import the dataset, unless the column is a character class.
It's up to you whether you want to enter NA into your spreadsheet to indicate missing data (NA in a spreadsheet will be recognized as `NA` by R).
I usually do so to distinguish missing data from empty cells where I forgot to enter data.

### Detecting `NA`s

R is great at handling `NA`s.
For example, below is a dataframe (`DF`) with two columns of numbers, some of which have `NA`s.
I have created `DF` for you.

```{r NAs-setup}
DF <- data.frame(x = c(1, NA, 3, 6, 10, NA, -2), y = c(NA, NA, 2, 5, 14, 3, 1))
```

```{r NAs, exercise = TRUE}
```

<div id="NAs-hint">
`x_df <- DF[, 1]`

`sum(is.na(x_df))`

`x_df[!is.na(x_df)]`
or
`x_df[-which(is.na(x_df))]`
</div>

`is.na()` is a function that returns a logical vector, matrix, or dataframe (i.e., whatever object you're investigating), where elements are `TRUE` if they are `NA`.
Try it out on `DF` above.

Therefore, `sum(is.na(DF))` will tell you how many `NA`s are in the dataframe.

Now create a new vector called `x_df` that is the first column from `DF`.
How many `NA`s are in this vector?
Can you figure out how to use `is.na()` to remove `NA`s from your vector.
Click "Hint" if you're stuck. 

`complete.cases()` is a useful function that returns a logical vector where `TRUE` indicates rows without `NA`s.
Thus, to remove `NA`s from the dataframe `DF`, you would enter `DF[complete.cases(DF), ]`.

### Functions

Many functions have an argument `na.rm` that will remove `NA`s if `TRUE`.
For example, enter `mean(x_df, na.rm = TRUE)` to calculate the mean of `x_df` with `NA`s removed.
What happens when you set `na.rm = FALSE` (the default)?

```{r NA_mean-setup, echo = FALSE}
DF <- data.frame(x = c(1, NA, 3, 6, 10, NA, -2), y = c(NA, NA, 2, 5, 14, 3, 1))
x_df <- DF[, 1]
```

```{r NA_mean, exercise = TRUE}
```

This result is good because you always want to be in control of your data and analyses.
That is, you don't want R using a function on data that has `NA`s you don't know about.
It's better for R to return `NA` as the default, and make you actively ignore `NA`s by setting `na.rm = TRUE`. 


## Spaces & special characters in names

It is good practice to never use spaces in names; instead, use underscores, periods, or camel case (e.g., `human_height`, `human.height`, `humanHeight`).
Likewise, never use special characters (e.g., `!`, `@`, `#`, `/`, `*`, `&`, `?`, `()`) in names.
We will see what kinds of problems occur in R by including these things in names.

But before we do so, a related note: **remember to keep your names short but informative, and use lower case instead of upper case.**
All this just saves you time when typing and coding.

### Objects

R won't even allow you to use spaces in object names (e.g., try entering `x y <- 1` and see what happens).

```{r obj, exercise = TRUE}
```

You can probably already predict why certain special characters are problematic in R.
For example, `!` means "not" in logical statements, `#` will comment out your code so it doesn't run, `/` is division, `*` is multiplication, and `&` means AND in logical statements.
For the most part, if you try to include these special characters in object names, R will return an error.
Try out some examples above (e.g., `x / y <- 10`) to see why special characters in object names are problematic.

Sometimes, including special characters in object names will do things besides assigning something to an object name.
For example, if you use `=` as the assignment operator, `x!=10` is actually asking if the elements in `x` are not equal to `10`, which is not at all what you wanted!
Similarly, `x#=10` comments out `=10`, such that R will only run `x`. 


### Character strings

Here, spaces and special characters are actually not problematic.
As an example, create a vector of character strings, some of which have spaces or special characters in them.

```{r char, exercise = TRUE}
```

<div id = "char_spaces-hint">
I went with `x <- c("andrew!", "andrew?", "andrew du")`.

To subset out `"andrew du"`, for example, I entered `x[x == "andrew du"]`.
</div>

Now try to subset out one of the character strings with special characters.

You'll see that it works just fine, so spaces or special characters in character strings are okay (i.e., spaces/special characters are fine as long as they're surrounded by quotation marks).

### Variable names

Let's see what happens when you create a dataframe, wherein variable names have a space or special character in them.
I've provided you the code on how to do so.
Note that you have to use character strings (i.e., quotation marks) to define variable names with spaces or special characters.
Try out different special characters to see what happens.

```{r variab, exercise = TRUE}
DF <- data.frame("mass(kg)" = 1:10, "upper case" = LETTERS[1:10], lower_case = letters[1:10])
```

Use `colnames()` to see what R does to spaces and special characters in variables names.

R has automatically transformed spaces and special characters into periods!
This can cause headaches and confusion if you try to subset out a variable, which you know as `mass(kg)`, but is now represented as `mass.kg.`.

Note that the same transformation of spaces and special characters into periods happens when you import into R a spreadsheet that has spaces or special characters in the variable names.

### Summary

Even though spaces and special characters work for character strings, they present problems for object and variable names.
Because of this, **it's just easier to not use spaces or special characters in names at all (this includes file names)!**


## Multiple data pieces in a cell

An important rule in data organization is that each spreadsheet cell should contain only one piece of data.
The best way to illustrate this rule is to look at how it's violated and how this affects R.

### How the rule is violated

We're going to use a fake dataset I created.
For me to import the dataset for you, you need to first install the `RCurl` package on your computer.
Do this using `install.packages("RCurl", dep = TRUE)` (you need to do this in RStudio and not in the tutorial).

This is what the dataset looks like in spreadsheet form:

![](https://github.com/andrewdu1/ANTH674/blob/master/Datasets/multData_perCell_image.jpg?raw=true){width="50%"}

We can imagine that this is a dataset of 10 individuals from some imaginary animal, where we measured their mass, age, and height.
(The units for height are whatever you want them to be, though this is bad practice; it should be clear in the dataset or metadata what the units are)

We can already see some violations of our "one piece, one cell" rule:

1. The "mass" column has both the number and the unit (i.e., two pieces of data).
Better practice would be to put the numbers and units in different columns, or to indicate in the "mass" variable name that the units are in kg (e.g., "mass_kg").
2. Subject 3 has an age estimate that is questionable (i.e., 3?).
This combines two pieces of data: the age estimate (i.e., 3) and its uncertainty (i.e., ?).
Better practice would be to create an extra column noting that this measurement is uncertain.
3. Subject 4 has two measurements for height separated by a semicolon.
Perhaps this is because two measurements were taken at two different periods, between which the subject grew.
This is also poor data practice.

### How these violations affect R

In R, each column within a dataframe can be a different class (e.g., numeric, character, factor), but all elements *within* a column must be the same class.
Let's see what happens when we import the above spreadsheet, where this is *not* the case.

The dataset is in a dataframe called `mult_data`.
Use `head()` to look at the dataframe structure.

```{r multData-setup, message = FALSE, echo = FALSE}
mult_data <- readr::read_csv(url("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/multData_perCell.csv"))
```

```{r multData, exercise = TRUE}
```

You can enter `sapply(mult_data, class)` to see the class of each variable.

As you can see, the inclusion of units in the `mass` column has coerced the entire column to be characters.
This means we cannot analyze nor plot the mass numbers themselves.
A similar thing has happened when we included `?` in `age` for Subject 3: that one character has forced the enter column into a character class.
And the same thing has happened with `height` because of the semicolon.
In sum, the inclusion of multiple pieces of data has forced our numbers to be characters, rendering them unanalyzable.

### How to fix the issue

One way would be to fix the issues by hand in the original spreadsheet, but that can be tedious, especially for the `mass` column.

We can instead use the `substr()` and `nchar()` functions to extract substrings from a character vector (**NB:** this only works for characters!).
What do I mean by this?

Imagine we have a character called `"andrew"`, and we want to extract the first to penultimate letters.
`nchar()` tells us how many letters are in `"andrew"`, so we would extract our desired letters by entering `substr("andrew", 1, nchar("andrew") - 1)`.
Try it out below.

```{r multData1-setup, message = FALSE, echo = FALSE}
mult_data_url <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/multData_perCell.csv")

mult_data <- read.csv(text = mult_data_url)
```

```{r multData1, exercise = TRUE}
```

<div id = "multData1-hint">
`mass <- mult_data$mass`

`mass_trim <- substr(mass, 1, nchar(mass) - 3)`

`mass_trim_num <- as.numeric(mass_trim)`

`mult_data$mass <- mass_trim_num`

`class(mult_data$mass)`
</div>

So, we can automate trimming off the last three "letters" (i.e., `" kg"`) for each element in the `mass` column.

1. Save the `mass` column from `mult_data` into a new object called `mass` (this is just so you don't have to type `mult_data$mass` in its entirety multiple times, which also makes the code easier to read).
2. Trim off the last three letters using `substr()` and `nchar()`, and save the result to a new object called `mass_trim`.
3. `mass_trim` is still a character vector, however, so we have to transform it into a numeric one using `as.numeric()`.
Save the resulting numeric vector to `mass_trim_num`. 
4. Now we can replace `mass` in `mult_data` with `mass_trim_num`.
5. Double-check that `mult_data$mass` is now numeric with `class(mult_data$mass)`.

Click "Hint" if you're stuck.

We can also use `substr()` and `nchar()` to remove the `?` from the `age` column.
We can figure out which element has the `?` using `grep()` or `grepl()`.
**NB:** finding question marks using `grep()` or `grepl()` is slightly complicated: you have to use `"//?"` instead of `"?"`.

The `5; 6` in column `height` can be split using `strsplit()`, though I won't go into the details of how to do this (you can look at the help file and try it out yourself if you'd like).
The trickier part is what to do with the `5` and `6`.
Delete one of the numbers?
Average them?
Include both data points, which would require a slight restructing of the dataset (e.g., including a new column to accommodate multiple height estimates)?
The answer will depend on your research question and what you aim to accomplish with your analyses.

**A better solution to all the problems above is to input your data into a spreadsheet in the proper format to begin with!
Remember, one piece of data for each cell!**


## Exercise 2: Cleaning data

I have created a fake dataset of stone tool measurements (`stone_tools`), where the first column is raw material type, and the second column is length.
You will have to clean the dataset using what you learned, before you can answer the following questions.

```{r exer2-setup, echo = FALSE}
stone_tools <- data.frame(raw_material = 
                            c("Basalt", 
                              "flint?", 
                              rep("quartz", 3), 
                              "Quarz", 
                              "Quartz", 
                              "FLint", 
                              rep("quartz ", 2), 
                              "Baslat", 
                              "basalt", 
                              "basalt", 
                              rep("chert", 3)), 
                          length = c("6 cm",
                                     "100 mm",
                                     "2 cm",
                                     "5 cm",
                                     "11 cm",
                                     "2 cm",
                                     NA,
                                     "8 cm",
                                     "7 cm",
                                     "10 cm",
                                     "10 cm",
                                     NA,
                                     NA,
                                     "5 cm",
                                     "6 cm",
                                     "9 cm"))

```

1. How many stone tools are in the dataset?
How many raw material types are there? 
How many stone tools are there within each raw material type?

2. What is the average stone tool length across all raw material types?
What is the average stone tool length for each raw material type?

```{r exer2, exercise = TRUE}
# Click the link below for solution code
```

[Click this link for solution code](https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Code/Week2_exer2_solutions.txt) (I had to post my code on my GitHub because it was too long and got cut off using the "Solution" button).


```{r exer2_solutions, eval = FALSE, echo = FALSE}
# I will create a new dataset to clean, so I can preserve the old, dirty one
stone_tools_clean <- stone_tools


# standardize raw material names. 
# transform factors to characters first
stone_tools_clean$raw_material <- as.character(stone_tools_clean$raw_material)

# If the following is too busy, you can break up the code by assigning stone_tools_clean$raw_material to a different object first 
stone_tools_clean$raw_material[grep("bas", stone_tools_clean$raw_material, ignore.case = TRUE)] <- "basalt" 
stone_tools_clean$raw_material[grep("flint", stone_tools_clean$raw_material, ignore.case = TRUE)] <- "flint"
stone_tools_clean$raw_material[grep("quar", stone_tools_clean$raw_material, ignore.case = TRUE)] <- "quartz"
# chert is fine as is

# transform back into factors
stone_tools_clean$raw_material <- as.factor(stone_tools_clean$raw_material)


# Question 1a
nrow(stone_tools)

# Question 1b
length(unique(stone_tools_clean$raw_material))

# Question 1c
table(stone_tools_clean$raw_material)


# Now clean the length measurements by trimming the units off
# need to transform factors to characters first
stone_tools_clean$length <- as.character(stone_tools_clean$length)

# Again, if the following code is too busy, you can save stone_tools_clean$length to a new object first
length_trim <- substr(stone_tools_clean$length, 1, nchar(stone_tools_clean$length) - 3)

# save trimmed numbers to stone_tools_clean$length while transforming into numeric class
stone_tools_clean$length <- as.numeric(length_trim)

# there is one huge outlier (can be seen using a histogram, which we will cover next lecture)
hist(stone_tools_clean$length)

# we can extract the outlier length using max(), while setting na.rm=TRUE to remove NAs
# see the help file for max() if you don't know what it does
outlier_length <- max(stone_tools_clean$length, na.rm = TRUE)

# we can use grep to find this number in the original dataset to see what's going on (it was measured in mm, not cm)
stone_tools$length[grep(outlier_length , stone_tools$length)]

# transform back into cm
# again, if code is too busy, you can break it up by saving stone_tools_clean$length to a new object first
stone_tools_clean$length[which(stone_tools_clean$length == outlier_length)] <- outlier_length / 10 

# double-check to see if outlier is gone
hist(stone_tools_clean$length)

  
# Question 2a
mean(stone_tools_clean$length, na.rm = TRUE)

# Question 2b
mean(stone_tools_clean$length[stone_tools_clean$raw_material == "basalt"], na.rm = TRUE)
mean(stone_tools_clean$length[stone_tools_clean$raw_material == "chert"], na.rm = TRUE)
mean(stone_tools_clean$length[stone_tools_clean$raw_material == "flint"], na.rm = TRUE)
mean(stone_tools_clean$length[stone_tools_clean$raw_material == "quartz"], na.rm = TRUE)

# Here is a quicker way to answer Question 2b.
# remove NAs first
stone_tools_clean_noNA <- stone_tools_clean[complete.cases(stone_tools_clean), ]

# check to see if NAs were removed
sum(is.na(stone_tools_clean_noNA))

tapply(stone_tools_clean_noNA$length, stone_tools_clean_noNA$raw_material, mean)
# tapply() is a handy function that will apply a function (third argument) to groups of elements sharing the same factor level (second argument) inside a vector (first argument)

# if I wanted to use tapply() with NAs still in stone_tools_clean$length, I would need to do one extra step: define the function, so I can use the na.rm argument. This is something we'll cover in a future lecture. 
tapply(stone_tools_clean$length, stone_tools_clean$raw_material, function(x) mean(x, na.rm = TRUE))
```


## Non-rectangular data

A **rectangular dataset** is one where rows correspond to observations and columns correspond to variables.
*Only* the first row should contain variable names. 
We will see what happens when this is not the case, using the non-rectangular dataset example from Figure 2b in Broman & Woo (2018).

I will import the dataset for you, which is a spreadsheet that looks exactly like it does in Figure 2b:

![](https://github.com/andrewdu1/ANTH674/blob/master/Datasets/BromanWoo2018_Fig2b.jpg?raw=true){width="80%"}

```{r non_rect-setup, message = FALSE, echo = FALSE}
csv_url <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/Fig2b_BromanWoo2018.csv")

non_rect <- read.csv(text = csv_url)
```

Now bring up the dataset, which is in the object `non_rect`.
You can see that R has interpreted the first spreadsheet row as variable names, even though there were only two filled cells with the rest empty.
Empty cells are given arbitrary variable names (e.g., `X`, `X.1`, `X.2`, and so on).
You can also see what happens when you start a variable name with a number: R automatically puts an `X` in front of it (e.g., `X1min`).
So, never start variable names with numbers!

```{r non_rect, exercise = TRUE}
```

The second spreadsheet row includes variables names, but R interprets them as real data, which is a mix of character strings and `NA`s.
This in turn messes up the class of variables in each column.
Use `sapply(non_rect, class)` to see what class each column is.
You can see that those columns with character strings (e.g., `"normal"`, `"mutant"`) forced the entire column to be characters, even though there are numbers too.

**Remember, R interprets only the first spreadsheet row as variable names!
The other rows should be data only!**

Furthermore, knowing now that R subsets and performs operations/calculations on data by rows and columns, this dataset would be a nightmare to analyze: columns are a mixture of strains (e.g., "A", "B"), which are parsed too finely by genotype (e.g., "normal", "mutant"), replicates, and minutes (e.g., "1", "5"); rows are a horrendous mixture of all of these.
For example, how would you subset out those measurements for strain A with normal genotypes, across all replicates and minutes (i.e., cells B3, C3, F3, and G3)?
It would be a HUGE pain, especially if this was a large dataset!

### Solution

This is pretty much unsalvageable in R, or at least it would be easier to fix in the original spreadsheet itself.
A better solution would be to not input data this way in the first place.
The data should have originally been entered in a rectangular format like so (Figure 3 from Broman & Woo 2018):

![](https://github.com/andrewdu1/ANTH674/blob/master/Datasets/BromanWoo2018_Fig3.jpg?raw=true){width="80%"}

Now it's simple to subset out those measurements for strain A with normal genotypes, across all replicates and minutes.
Calling the dataframe `d`, the code would be `subset(d, strain == "A" & genotype == "normal", response)` or `d$response[d$strain == "A" & d$genotype == "normal"]`.

**Remember, always keep your spreadsheets rectangular!**


## Relating different datasets

In order to keep datasets rectangular, sometimes you have to divide them up into separate rectangles.
For example, let's load two published datasets from Du et al. (2019).

```{r relate_data-setup, message = FALSE, echo = FALSE}
csv_url_iso <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/Duetal2019_isotopes.csv")
iso <- read.csv(text = csv_url_iso)

csv_url_abund <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/Duetal2019_abundances.csv")
abund <- read.csv(text = csv_url_abund, row.names = 1)
```

`iso` is a dataframe with stable carbon isotope measurements from fossil tooth enamel and ancient soil carbonates for geological members in eastern Africa.
`abund` is a dataframe with abundances of taxa whose teeth were analyzed from these members.
Use `head()` to see what these datasets are like.

```{r relate_data, exercise = TRUE}
```

You can see that these two datasets share two variables that link them together: `iso$member` is the column names for `abund`, and `iso$taxon` is the row names for `abund`.
You can double-check this visually by comparing `sort(unique(iso$member))` with `sort(colnames(abund))` and `sort(unique(iso$taxon))` with `sort(rownames(abund))`.
You can do a more rigorous check with the `identical()` function, which takes two R objects as separate arguments to see if they are *exactly* equal (e.g., `identical(sort(unique(iso$member)), sort(colnames(abund)))`).

You can see how it would be difficult to combine these two datasets into one that is still rectangular.
To illustrate, each taxon from each member in `abund` has only one number associated with it: the taxon's abundance from that member.
In `iso`, on the other hand, each taxon from each member is associated with multiple enamel isotope measurements. 
These differences in data sizes for a given taxon and member make it difficult to combine these two datasets and still maintain a rectangular format.

But because the datasets are linked by shared taxon and member names, it is straightforward to analyze them together.
For example, we can look at the enamel isotope measurements and abundance for Aepycerotini from the Sidi Hakoma Member.
FYI, this is what Aepycerotini (e.g., an impala) looks like:

![](https://upload.wikimedia.org/wikipedia/commons/e/e1/Trotting_impala_ram%2C_crop.jpg){width="60%"}

And this is what Hadar (where the Sidi Hakoma Member is) looks like:

![](https://iho.asu.edu/sites/default/files/images_asunews/hadar_w_students_working.jpg){width="70%"}

Subset out the enamel isotope measurements (`d13C`) for Aepycerotini and Sidi Hakoma (`iso$data.type == "enamel"`, `iso$taxon == "Aepycerotini`, `iso$member == "SidiHakoma`).
(I have kept the datasets loaded for you.)

```{r relate_data_example-setup, echo = FALSE, message = FALSE}
csv_url_iso <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/Duetal2019_isotopes.csv")
iso <- read.csv(text = csv_url_iso)

csv_url_abund <- RCurl::getURL("https://raw.githubusercontent.com/andrewdu1/ANTH674/master/Datasets/Duetal2019_abundances.csv")
abund <- read.csv(text = csv_url_abund, row.names = 1)
```

```{r relate_data_example, exercise = TRUE}
```

<div id = "relate_data_example-hint">
Because you want to subset out rows that meet *all* three criteria, you want to use `&` in your logical statement.
</div>

Now subset out the abundance for this taxon in this member (subsetting data using row and column names is easy in R: `abund["Aepycerotini", "SidiHakoma"]`; you could also do `abund$SidiHakoma[rownames(abund) == "Aepycerotini"]`). 

Now we can do whatever analyses we'd like with these two pieces of related data!

**Remember, always relate different datasets to each other with at least one shared variable (e.g.,** `member`**,** `taxon`**), whose names are *exactly* the same!**


## Conclusion

You learned the what and why of data wrangling in lecture, and now you've learned the how in this R tutorial.
There is a lot of information in here, so I don't expect you to have learned and memorized everything right away. 
Think of this tutorial as an introduction to data wrangling in R and a reference that you can look back to when you need to remember how to do something.
I'm sure certain sections spoke to you more, as these are more relevant for your research questions and the datasets you work with (it's best to focus on learning these sections more thoroughly first).
Again, the best way to learn R is by doing, and the best way to retain that information is by doing it over and over (i.e., practice makes perfect!).

![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png){width="80%"}

By learning how to fix data issues in R, you have learned how data should be structured and entered into a spreadsheet in the first place.
This will save you time and energy later on, as there is less data cleaning to do in R.
Having your data in a clean format also saves time for your colleagues when data are shared or published.

As a reminder, here are the general rules for good data organization:

1. Use consistent names
2. Enter missing data as NA
3. Don't use spaces or special characters in names
4. Keep names short but informative, and use lower case instead of upper case
5. Each spreadsheet cell should have only one piece of data
6. Always keep your data rectangular
7. Relate different datasets using shared variable(s) that have exactly the same names

Data wrangling is an intuitive process (e.g., I was never formally taught how to data wrangle).
Once you know what your research question is and what data and tests you need, it will become immediately clear how you should clean, subset, and organize your data.
This R tutorial gives you the tools for doing the latter.
